{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cffi\n",
    "from pynq import Overlay\n",
    "# load Base Overlay\n",
    "Overlay(\"/home/xilinx/pynq/bitstream/base.bit\").download()\n",
    "\n",
    "from pynq.drivers import xlnk\n",
    "import chainer\n",
    "from chainer import links as L\n",
    "from chainer import functions as F\n",
    "from chainer import Variable\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = chainer.datasets.get_mnist()\n",
    "\n",
    "x, label = train[0]\n",
    "\n",
    "img = x.reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = x[np.newaxis,:]\n",
    "input_image = input_image.astype(np.float32)\n",
    "input_image = chainer.Variable(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_units, n_out):\n",
    "        super(MLP, self).__init__(\n",
    "            # the size of the inputs to each layer will be inferred\n",
    "            l1=L.Linear(None, n_units),  # n_in -> n_units\n",
    "            l2=L.Linear(None, n_units),  # n_units -> n_units\n",
    "            l3=L.Linear(None, n_out),  # n_units -> n_out\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        h3 = self.l3(h2)\n",
    "        return h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.72933567e-13   1.29591760e-08   4.09196055e-08   2.45058932e-03\n",
      "    3.96322804e-23   9.97549355e-01   1.99584192e-15   1.14123750e-12\n",
      "    1.81231957e-11   1.20258378e-11]]\n",
      "result 5\n",
      "seikai 5\n"
     ]
    }
   ],
   "source": [
    "mlp_cpu = MLP(n_units=32, n_out=10)\n",
    "\n",
    "resume = \"./mnist_iter_12000.npz\"\n",
    "chainer.serializers.load_npz(resume, mlp_cpu)\n",
    "\n",
    "h = F.softmax(mlp_cpu(input_image))\n",
    "y = F.argmax(h)\n",
    "\n",
    "print(h.data)\n",
    "print(\"result\", y.data)\n",
    "print(\"seikai\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FPGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 実際はon-the-fly\n",
    "bitfile = \"./bitstream.bit\"\n",
    "libfile = \"./src/libaccel.so\"\n",
    "ffi = cffi.FFI()\n",
    "ffi.cdef(\"int _Z18_p0_mmult_accel1_0PfS_S_iii(float*, float*, float*, int, int, int);\")\n",
    "lib = ffi.dlopen(libfile)\n",
    "accFn = lib._Z18_p0_mmult_accel1_0PfS_S_iii\n",
    "Overlay(bitfile).download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "memmanager = xlnk.xlnk()\n",
    "\n",
    "def init_contiguous_ndarray(size=(32,32), dtype=\"float\"):\n",
    "    buf_size = size[0]*size[1]\n",
    "    buf = memmanager.cma_alloc(buf_size, data_type=dtype)\n",
    "    v_cdata = ffi.buffer(buf,  buf_size * ffi.sizeof(dtype))\n",
    "    v = np.frombuffer(v_cdata, dtype=np.float32).reshape(size)\n",
    "    #print(v, buf, v_cdata)\n",
    "    print(\"cma alloc\")\n",
    "    return v, buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cma alloc\n",
      "cma alloc\n",
      "cma alloc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_nrows, x_ncols = 32, 32\n",
    "w_nrows, w_ncols = 32, 32\n",
    "y, y_cdata = init_contiguous_ndarray((x_nrows, w_nrows))\n",
    "x, x_cdata = init_contiguous_ndarray((x_nrows, x_ncols))\n",
    "w, w_cdata = init_contiguous_ndarray((w_nrows, w_ncols))\n",
    "accFn(x_cdata, w_cdata, y_cdata, x_nrows, w_nrows, x_ncols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def copy_cma(array):\n",
    "    x, cdata = init_contiguous_ndarray(array.shape)\n",
    "    np.copyto(x, array)\n",
    "    return x, cdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### memmanager.xlnk_reset()\n",
    "for i in range(5):\n",
    "    x_nrows, x_ncols = 3, 2\n",
    "    w_nrows, w_ncols = 2, 2\n",
    "    \n",
    "    x = np.random.uniform(-1,1,(x_nrows, x_ncols))\n",
    "    w = np.random.uniform(-1,1,(w_nrows, w_ncols))\n",
    "\n",
    "    x, x_cdata = copy_cma(x)\n",
    "    w, w_cdata = copy_cma(w)\n",
    "    #y, y_cdata = init_contiguous_ndarray((x_nrows, w_nrows))\n",
    "    y, y_cdata = init_contiguous_ndarray((w_nrows, x_nrows))\n",
    "    \n",
    "    \n",
    "    #y = np.asfortranarray(y)\n",
    "    accFn(x_cdata, w_cdata, y_cdata, x_nrows, w_nrows, x_ncols)\n",
    "    y = y.T\n",
    "    #y = np.asfortranarray(y)\n",
    "    y_ = x.dot(w.T)\n",
    "    \n",
    "    if np.allclose(y, y_, rtol=1e-04, atol=1e-04):\n",
    "        print('OK')\n",
    "    else:\n",
    "        print(\"NG\")\n",
    "        print(y.shape)\n",
    "        print(y_)\n",
    "        print(y)\n",
    "        print(y.flags)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class _Linear(L.Linear):\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        if self.has_uninitialized_params:\n",
    "            print('init')\n",
    "            self._initialize_params(x.size // x.shape[0])\n",
    "            \n",
    "        if not hasattr(x, \"cdata\"):\n",
    "            # copy\n",
    "            #print(\"input x is not CMA. copy...\")\n",
    "            x_, x_cdata = init_contiguous_ndarray(x.shape)\n",
    "            x_ = Variable(x_)\n",
    "            x_.cdata = x_cdata\n",
    "            np.copyto(x_.data, x.data)\n",
    "            #print(x.data)\n",
    "            x = x_\n",
    "            \n",
    "            #print(x_.data)\n",
    "\n",
    "        #y = Linear()(x, self.W)\n",
    "        #print(type(x), type(self.W))\n",
    "        #y = self.linear(x.data, self.W.data)\n",
    "        y = self.linear(x, self.W)\n",
    "\n",
    "        return y #chainer.Variable(y)\n",
    "\n",
    "    def linear(self, x, w):\n",
    "        #import cffi\n",
    "        self.ffi = ffi #cffi.FFI()\n",
    "        \n",
    "        if False:\n",
    "            import overlay, cffi\n",
    "            self.accel_fun =lib.mmult_accel1\n",
    "        else:\n",
    "            self.accel_fun = accFn #lib.__Z12mmult_accel1PfS_S_iii\n",
    "        \n",
    "        x_nrows, x_ncols = x.shape\n",
    "        w_nrows, w_ncols = w.shape\n",
    "        #y = np.zeros((x_nrows, w_nrows)).astype(np.float32) #XXX\n",
    "\n",
    "        #x_cdata = self.ffi.from_buffer(x.data)\n",
    "        #w_cdata = self.ffi.from_buffer(w.data) # not contigunous ?\n",
    "        x_cdata = x.cdata\n",
    "        w_cdata = w.cdata\n",
    "        \n",
    "        # tukaimawasitai\n",
    "        y, y_cdata = init_contiguous_ndarray((x_nrows, w_nrows))\n",
    "        y = Variable(y)\n",
    "        y.cdata = y_cdata\n",
    "        \n",
    "        self.accel_fun(x_cdata, w_cdata, y_cdata, x_nrows, w_nrows, x_ncols)\n",
    "        #print(y.cdata)\n",
    "        return y\n",
    "    \n",
    "    \n",
    "    def add_param(self, name, shape, dtype=np.float32, initializer=None):\n",
    "        \"\"\"Registers a parameter to the link.\n",
    "        \"\"\"\n",
    "        d = self.__dict__\n",
    "        if name in d:\n",
    "            raise AttributeError(\n",
    "                'cannot register a new parameter %s: attribute exists'\n",
    "                % name)\n",
    "        if initializer is not None:\n",
    "            raise AttributeError('initializer is not supported')\n",
    "        \n",
    "        #data = self.xp.full(shape, numpy.nan, dtype=dtype)\n",
    "        \n",
    "        data, cdata = init_contiguous_ndarray(shape)\n",
    "        var = Variable(data, volatile='auto', name=name)\n",
    "        var.cdata = cdata\n",
    "        print('init model cma array', name, cdata, var)\n",
    "        \n",
    "        self._params.append(name)\n",
    "        d[name] = var\n",
    "        if name in self._uninitialized_params:\n",
    "            del self._uninitialized_params[name]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP_FPGA(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_units, n_out):\n",
    "        super(MLP_FPGA, self).__init__(\n",
    "            # the size of the inputs to each layer will be inferred\n",
    "            l1=_Linear(None, n_units, nobias=True),  # n_in -> n_units\n",
    "            l2=_Linear(None, n_units, nobias=True),  # n_units -> n_units\n",
    "            l3=_Linear(None, n_out, nobias=True),  # n_units -> n_out\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if True:\n",
    "            h1 = self.l1(x)\n",
    "            print(h1.data)\n",
    "            h2 = self.l2(h1)\n",
    "            h3 = self.l3(h2)\n",
    "            return h3\n",
    "        \n",
    "        h = self.l1(x)\n",
    "        print(h)\n",
    "        h1 = F.relu(h)\n",
    "        print(\"h1 done\")\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        print(\"h2 done\")\n",
    "        h3 = self.l3(h2)\n",
    "        print(\"h3 done\")\n",
    "        print(x.shape)\n",
    "        print(h1.shape)\n",
    "        print(h1.data)\n",
    "        print(h2.shape)\n",
    "        print(h2.data)\n",
    "        print(h3.shape)\n",
    "        print(h3.data)\n",
    "        print(\"call done\")\n",
    "        return h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cma alloc\n",
      "init model cma array W <cdata 'float *' 0x368fd000> W\n",
      "cma alloc\n",
      "init model cma array W <cdata 'float *' 0x368fc000> W\n",
      "cma alloc\n",
      "init model cma array W <cdata 'float *' 0x301ed000> W\n"
     ]
    }
   ],
   "source": [
    "memmanager.xlnk_reset()\n",
    "mlp_fpga = MLP_FPGA(n_units=32, n_out=10)\n",
    "\n",
    "resume = \"./mnist_iter_12000.npz\"\n",
    "chainer.serializers.load_npz(resume, mlp_fpga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 入力画像をCMA-arrayに変換\n",
    "if False:\n",
    "    in_fpga, cdata = init_contiguous_ndarray((1, 784))\n",
    "    in_fpga = Variable(in_fpga)\n",
    "    in_fpga.cdata = cdata\n",
    "    print('init input cma array', cdata)\n",
    "    np.copyto(in_fpga.data, input_image.data)\n",
    "else:\n",
    "    in_fpga = input_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Buffer Count': 3,\n",
       " 'CMA Memory Available': 23445504,\n",
       " 'CMA Memory Usage': 105728}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memmanager.cma_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cma alloc\n",
      "cma alloc\n",
      "[[ 3.05095577 -2.61691952  2.55680013  4.07168865  1.99023378  1.09072948\n",
      "  -1.82831872  4.49700737  5.57241726 -4.70780516 -2.25808644 -4.83468103\n",
      "   3.18601227 -3.28089046 -0.62773103 -0.6149773  -0.7455532   2.0017643\n",
      "   0.73404318  3.90470552  3.48775458  3.08954358 -0.47251615 -0.90851831\n",
      "  -0.327535    3.60635543  3.32248259 -3.12803578  3.87468791  6.82556391\n",
      "  -0.1521184   4.46334553]]\n",
      "cma alloc\n",
      "cma alloc\n",
      "[[ 0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1]]\n",
      "result 0\n",
      "seikai 5\n"
     ]
    }
   ],
   "source": [
    "h = mlp_fpga(in_fpga)\n",
    "#print(h.data)\n",
    "h = F.softmax(h)\n",
    "print(h.data)\n",
    "y = F.argmax(h)\n",
    "print(\"result\", y.data)\n",
    "print(\"seikai\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[[ 3.05095577 -2.61691952  2.55680013  4.07168865  1.99023378  1.09072948\n",
    "  -1.82831872  4.49700737  5.57241726 -4.70780516 -2.25808644 -4.83468103\n",
    "   3.18601227 -3.28089046 -0.62773103 -0.6149773  -0.7455532   2.0017643\n",
    "   0.73404318  3.90470552  3.48775458  3.08954358 -0.47251615 -0.90851831\n",
    "  -0.327535    3.60635543  3.32248259 -3.12803578  3.87468791  6.82556391\n",
    "  -0.1521184   4.46334553]]\n",
    "cma alloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00243445, -0.01467556, -0.03736734, ..., -0.00618258,\n",
       "        -0.05827544,  0.01092706],\n",
       "       [-0.00656789, -0.01566242, -0.00783664, ...,  0.03368339,\n",
       "        -0.03029446, -0.00054984],\n",
       "       [-0.01208445,  0.03738809,  0.03690353, ..., -0.03964131,\n",
       "        -0.00824925, -0.0160101 ],\n",
       "       ..., \n",
       "       [-0.00147085, -0.00091083,  0.00710204, ..., -0.02693082,\n",
       "        -0.04154285,  0.00159526],\n",
       "       [-0.00618948, -0.00190609, -0.00456239, ...,  0.02179371,\n",
       "         0.00387135, -0.06620802],\n",
       "       [-0.00815233, -0.01577895,  0.01509112, ...,  0.00082192,\n",
       "        -0.03644796, -0.01761495]], dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_fpga.l1.W.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loops, best of 3: 9.2 ms per loop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TimeitResult : 2 loops, best of 3: 9.2 ms per loop>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " %timeit -n 2 -o mlp_cpu(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'chainer.variable.Variable'> <class 'chainer.variable.Variable'>\n",
      "<cdata 'float *' 0x30008000> <cdata 'float *' 0x30009000> <cdata 'float *' 0x30004000>\n",
      "<cdata 'float *' 0x30004000>\n",
      "<class 'chainer.variable.Variable'> <class 'chainer.variable.Variable'>\n",
      "<cdata 'float *' 0x30004000> <cdata 'float *' 0x30023000> <cdata 'float *' 0x30003000>\n",
      "<cdata 'float *' 0x30003000>\n",
      "<class 'chainer.variable.Variable'> <class 'chainer.variable.Variable'>\n",
      "<cdata 'float *' 0x30003000> <cdata 'float *' 0x30022000> <cdata 'float *' 0x30002000>\n",
      "<cdata 'float *' 0x30002000>\n",
      "<class 'chainer.variable.Variable'> <class 'chainer.variable.Variable'>\n",
      "<cdata 'float *' 0x30008000> <cdata 'float *' 0x30009000> <cdata 'float *' 0x30001000>\n",
      "<cdata 'float *' 0x30001000>\n",
      "<class 'chainer.variable.Variable'> <class 'chainer.variable.Variable'>\n",
      "<cdata 'float *' 0x30001000> <cdata 'float *' 0x30023000> <cdata 'float *' 0x30000000>\n",
      "<cdata 'float *' 0x30000000>\n",
      "<class 'chainer.variable.Variable'> <class 'chainer.variable.Variable'>\n",
      "<cdata 'float *' 0x30000000> <cdata 'float *' 0x30022000> <cdata 'float *' 0x2ffff000>\n",
      "<cdata 'float *' 0x2ffff000>\n",
      "<class 'chainer.variable.Variable'> <class 'chainer.variable.Variable'>\n",
      "<cdata 'float *' 0x30008000> <cdata 'float *' 0x30009000> <cdata 'float *' 0x2fffe000>\n",
      "<cdata 'float *' 0x2fffe000>\n",
      "<class 'chainer.variable.Variable'> <class 'chainer.variable.Variable'>\n",
      "<cdata 'float *' 0x2fffe000> <cdata 'float *' 0x30023000> <cdata 'float *' 0x2fffd000>\n",
      "<cdata 'float *' 0x2fffd000>\n",
      "<class 'chainer.variable.Variable'> <class 'chainer.variable.Variable'>\n",
      "<cdata 'float *' 0x2fffd000> <cdata 'float *' 0x30022000> <cdata 'float *' 0x2fffc000>\n",
      "<cdata 'float *' 0x2fffc000>\n",
      "<class 'chainer.variable.Variable'> <class 'chainer.variable.Variable'>\n",
      "<cdata 'float *' 0x30008000> <cdata 'float *' 0x30009000> <cdata 'float *' 0x2fffb000>\n",
      "<cdata 'float *' 0x2fffb000>\n",
      "<class 'chainer.variable.Variable'> <class 'chainer.variable.Variable'>\n",
      "<cdata 'float *' 0x2fffb000> <cdata 'float *' 0x30023000> <cdata 'float *' 0x2fffa000>\n",
      "<cdata 'float *' 0x2fffa000>\n",
      "<class 'chainer.variable.Variable'> <class 'chainer.variable.Variable'>\n",
      "<cdata 'float *' 0x2fffa000> <cdata 'float *' 0x30022000> <cdata 'float *' 0x2fff9000>\n",
      "<cdata 'float *' 0x2fff9000>\n",
      "<class 'chainer.variable.Variable'> <class 'chainer.variable.Variable'>\n",
      "<cdata 'float *' 0x30008000> <cdata 'float *' 0x30009000> <cdata 'float *' 0x2fff8000>\n",
      "<cdata 'float *' 0x2fff8000>\n",
      "<class 'chainer.variable.Variable'> <class 'chainer.variable.Variable'>\n",
      "<cdata 'float *' 0x2fff8000> <cdata 'float *' 0x30023000> <cdata 'float *' 0x2fff7000>\n",
      "<cdata 'float *' 0x2fff7000>\n",
      "<class 'chainer.variable.Variable'> <class 'chainer.variable.Variable'>\n",
      "<cdata 'float *' 0x2fff7000> <cdata 'float *' 0x30022000> <cdata 'float *' 0x2fff6000>\n",
      "<cdata 'float *' 0x2fff6000>\n",
      "<class 'chainer.variable.Variable'> <class 'chainer.variable.Variable'>\n",
      "<cdata 'float *' 0x30008000> <cdata 'float *' 0x30009000> <cdata 'float *' 0x2fff5000>\n",
      "<cdata 'float *' 0x2fff5000>\n",
      "<class 'chainer.variable.Variable'> <class 'chainer.variable.Variable'>\n",
      "<cdata 'float *' 0x2fff5000> <cdata 'float *' 0x30023000> <cdata 'float *' 0x2fff4000>\n",
      "<cdata 'float *' 0x2fff4000>\n",
      "<class 'chainer.variable.Variable'> <class 'chainer.variable.Variable'>\n",
      "<cdata 'float *' 0x2fff4000> <cdata 'float *' 0x30022000> <cdata 'float *' 0x2fff3000>\n",
      "<cdata 'float *' 0x2fff3000>\n",
      "2 loops, best of 3: 5.52 ms per loop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TimeitResult : 2 loops, best of 3: 5.52 ms per loop>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " %timeit -n 2 -o mlp_fpga(in_fpga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "memmanager.xlnk_reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
