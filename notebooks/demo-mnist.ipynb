{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cffi\n",
    "from pynq import Overlay\n",
    "# load Base Overlay\n",
    "Overlay(\"/home/xilinx/pynq/bitstream/base.bit\").download()\n",
    "\n",
    "from pynq.drivers import xlnk\n",
    "import chainer\n",
    "from chainer import links as L\n",
    "from chainer import functions as F\n",
    "from chainer import Variable\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = chainer.datasets.get_mnist()\n",
    "\n",
    "x, label = train[0]\n",
    "\n",
    "img = x.reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = x[np.newaxis,:]\n",
    "input_image = input_image.astype(np.float32)\n",
    "input_image = chainer.Variable(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_units, n_out):\n",
    "        super(MLP, self).__init__(\n",
    "            # the size of the inputs to each layer will be inferred\n",
    "            l1=L.Linear(None, n_units),  # n_in -> n_units\n",
    "            l2=L.Linear(None, n_units),  # n_units -> n_units\n",
    "            l3=L.Linear(None, n_out),  # n_units -> n_out\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        h3 = self.l3(h2)\n",
    "        return h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.72933567e-13   1.29591760e-08   4.09196055e-08   2.45058932e-03\n",
      "    3.96322804e-23   9.97549355e-01   1.99584192e-15   1.14123750e-12\n",
      "    1.81231957e-11   1.20258378e-11]]\n",
      "result 5\n",
      "seikai 5\n"
     ]
    }
   ],
   "source": [
    "mlp_cpu = MLP(n_units=32, n_out=10)\n",
    "\n",
    "resume = \"../examples/mnist/mnist_iter_12000.npz\"\n",
    "chainer.serializers.load_npz(resume, mlp_cpu)\n",
    "\n",
    "h = F.softmax(mlp_cpu(input_image))\n",
    "y = F.argmax(h)\n",
    "\n",
    "print(h.data)\n",
    "print(\"result\", y.data)\n",
    "print(\"seikai\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FPGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 実際はon-the-fly\n",
    "bitfile = \"../pynq_chainer/HLS/bitstream.bit\"\n",
    "libfile = \"../pynq_chainer/HLS/src/libaccel.so\"\n",
    "ffi = cffi.FFI()\n",
    "ffi.cdef(\"int _Z18_p0_mmult_accel1_0PfS_S_iii(float*, float*, float*, int, int, int);\")\n",
    "lib = ffi.dlopen(libfile)\n",
    "accFn = lib._Z18_p0_mmult_accel1_0PfS_S_iii\n",
    "Overlay(bitfile).download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "memmanager = xlnk.xlnk()\n",
    "\n",
    "def init_contiguous_ndarray(size=(32,32), dtype=\"float\"):\n",
    "    buf_size = size[0]*size[1]\n",
    "    buf = memmanager.cma_alloc(buf_size, data_type=dtype)\n",
    "    v_cdata = ffi.buffer(buf,  buf_size * ffi.sizeof(dtype))\n",
    "    v = np.frombuffer(v_cdata, dtype=np.float32).reshape(size)\n",
    "    #print(v, buf, v_cdata)\n",
    "    print(\"cma alloc\")\n",
    "    return v, buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cma alloc\n",
      "cma alloc\n",
      "cma alloc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_nrows, x_ncols = 32, 32\n",
    "w_nrows, w_ncols = 32, 32\n",
    "y, y_cdata = init_contiguous_ndarray((x_nrows, w_nrows))\n",
    "x, x_cdata = init_contiguous_ndarray((x_nrows, x_ncols))\n",
    "w, w_cdata = init_contiguous_ndarray((w_nrows, w_ncols))\n",
    "accFn(x_cdata, w_cdata, y_cdata, x_nrows, w_nrows, x_ncols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def copy_cma(array):\n",
    "    x, cdata = init_contiguous_ndarray(array.shape)\n",
    "    np.copyto(x, array)\n",
    "    return x, cdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cma alloc\n",
      "cma alloc\n",
      "cma alloc\n",
      "NG\n",
      "(3, 2)\n",
      "[[-1.29007959 -0.35883552]\n",
      " [ 0.32835293 -0.15911043]\n",
      " [-0.47456002 -0.64056128]]\n",
      "[[ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]]\n",
      "  C_CONTIGUOUS : False\n",
      "  F_CONTIGUOUS : True\n",
      "  OWNDATA : False\n",
      "  WRITEABLE : True\n",
      "  ALIGNED : True\n",
      "  UPDATEIFCOPY : False\n",
      "cma alloc\n",
      "cma alloc\n",
      "cma alloc\n",
      "NG\n",
      "(3, 2)\n",
      "[[-1.04454648 -0.74541163]\n",
      " [-0.02386647  0.3104001 ]\n",
      " [-0.40054369 -0.04571752]]\n",
      "[[ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]]\n",
      "  C_CONTIGUOUS : False\n",
      "  F_CONTIGUOUS : True\n",
      "  OWNDATA : False\n",
      "  WRITEABLE : True\n",
      "  ALIGNED : True\n",
      "  UPDATEIFCOPY : False\n",
      "cma alloc\n",
      "cma alloc\n",
      "cma alloc\n",
      "NG\n",
      "(3, 2)\n",
      "[[-0.64585561  0.78773791]\n",
      " [-0.40645465  0.73415315]\n",
      " [-0.42389965  0.18171066]]\n",
      "[[-0.64585561  0.78773791]\n",
      " [-0.40645465  0.73415315]\n",
      " [-0.42389965  0.18171066]]\n",
      "  C_CONTIGUOUS : False\n",
      "  F_CONTIGUOUS : True\n",
      "  OWNDATA : False\n",
      "  WRITEABLE : True\n",
      "  ALIGNED : True\n",
      "  UPDATEIFCOPY : False\n",
      "cma alloc\n",
      "cma alloc\n",
      "cma alloc\n",
      "NG\n",
      "(3, 2)\n",
      "[[-0.6050719   0.51083308]\n",
      " [ 0.68736738  1.21400881]\n",
      " [ 0.39497739 -0.13912609]]\n",
      "[[-0.6050719   0.51083308]\n",
      " [ 0.68736738  1.21400881]\n",
      " [ 0.39497739 -0.13912609]]\n",
      "  C_CONTIGUOUS : False\n",
      "  F_CONTIGUOUS : True\n",
      "  OWNDATA : False\n",
      "  WRITEABLE : True\n",
      "  ALIGNED : True\n",
      "  UPDATEIFCOPY : False\n",
      "cma alloc\n",
      "cma alloc\n",
      "cma alloc\n",
      "NG\n",
      "(3, 2)\n",
      "[[ 0.3852571   0.91810328]\n",
      " [-0.51785082 -1.22199798]\n",
      " [ 0.15439524  0.3595762 ]]\n",
      "[[ 0.3852571   0.91810328]\n",
      " [-0.51785082 -1.22199798]\n",
      " [ 0.15439524  0.3595762 ]]\n",
      "  C_CONTIGUOUS : False\n",
      "  F_CONTIGUOUS : True\n",
      "  OWNDATA : False\n",
      "  WRITEABLE : True\n",
      "  ALIGNED : True\n",
      "  UPDATEIFCOPY : False\n"
     ]
    }
   ],
   "source": [
    "memmanager.xlnk_reset()\n",
    "for i in range(5):\n",
    "    x_nrows, x_ncols = 3, 2\n",
    "    w_nrows, w_ncols = 2, 2\n",
    "    \n",
    "    x = np.random.uniform(-1,1,(x_nrows, x_ncols))\n",
    "    w = np.random.uniform(-1,1,(w_nrows, w_ncols))\n",
    "\n",
    "    x, x_cdata = copy_cma(x)\n",
    "    w, w_cdata = copy_cma(w)\n",
    "    #y, y_cdata = init_contiguous_ndarray((x_nrows, w_nrows))\n",
    "    y, y_cdata = init_contiguous_ndarray((w_nrows, x_nrows))\n",
    "    \n",
    "    \n",
    "    #y = np.asfortranarray(y)\n",
    "    accFn(x_cdata, w_cdata, y_cdata, x_nrows, w_nrows, x_ncols)\n",
    "    y = y.T\n",
    "    #y = np.asfortranarray(y)\n",
    "    y_ = x.dot(w.T)\n",
    "    \n",
    "    if np.allclose(y, y_, rtol=1e-04, atol=1e-04):\n",
    "        print('OK')\n",
    "    else:\n",
    "        print(\"NG\")\n",
    "        print(y.shape)\n",
    "        print(y_)\n",
    "        print(y)\n",
    "        print(y.flags)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class _Linear(L.Linear):\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        if self.has_uninitialized_params:\n",
    "            print('init')\n",
    "            self._initialize_params(x.size // x.shape[0])\n",
    "            \n",
    "        if not hasattr(x, \"cdata\"):\n",
    "            # copy\n",
    "            #print(\"input x is not CMA. copy...\")\n",
    "            x_, x_cdata = init_contiguous_ndarray(x.shape)\n",
    "            x_ = Variable(x_)\n",
    "            x_.cdata = x_cdata\n",
    "            np.copyto(x_.data, x.data)\n",
    "            #print(x.data)\n",
    "            x = x_\n",
    "            \n",
    "            #print(x_.data)\n",
    "\n",
    "        #y = Linear()(x, self.W)\n",
    "        #print(type(x), type(self.W))\n",
    "        #y = self.linear(x.data, self.W.data)\n",
    "        y = self.linear(x, self.W)\n",
    "\n",
    "        return y #chainer.Variable(y)\n",
    "\n",
    "    def linear(self, x, w):\n",
    "        #import cffi\n",
    "        self.ffi = ffi #cffi.FFI()\n",
    "        \n",
    "        if False:\n",
    "            import overlay, cffi\n",
    "            self.accel_fun =lib.mmult_accel1\n",
    "        else:\n",
    "            self.accel_fun = accFn #lib.__Z12mmult_accel1PfS_S_iii\n",
    "        \n",
    "        x_nrows, x_ncols = x.shape\n",
    "        w_nrows, w_ncols = w.shape\n",
    "        #y = np.zeros((x_nrows, w_nrows)).astype(np.float32) #XXX\n",
    "\n",
    "        #x_cdata = self.ffi.from_buffer(x.data)\n",
    "        #w_cdata = self.ffi.from_buffer(w.data) # not contigunous ?\n",
    "        x_cdata = x.cdata\n",
    "        w_cdata = w.cdata\n",
    "        \n",
    "        # tukaimawasitai\n",
    "        y, y_cdata = init_contiguous_ndarray((x_nrows, w_nrows))\n",
    "        y = Variable(y)\n",
    "        y.cdata = y_cdata\n",
    "        \n",
    "        self.accel_fun(x_cdata, w_cdata, y_cdata, x_nrows, w_nrows, x_ncols)\n",
    "        #print(y.cdata)\n",
    "        return y\n",
    "    \n",
    "    \n",
    "    def add_param(self, name, shape, dtype=np.float32, initializer=None):\n",
    "        \"\"\"Registers a parameter to the link.\n",
    "        \"\"\"\n",
    "        d = self.__dict__\n",
    "        if name in d:\n",
    "            raise AttributeError(\n",
    "                'cannot register a new parameter %s: attribute exists'\n",
    "                % name)\n",
    "        if initializer is not None:\n",
    "            raise AttributeError('initializer is not supported')\n",
    "        \n",
    "        #data = self.xp.full(shape, numpy.nan, dtype=dtype)\n",
    "        \n",
    "        data, cdata = init_contiguous_ndarray(shape)\n",
    "        var = Variable(data, volatile='auto', name=name)\n",
    "        var.cdata = cdata\n",
    "        print('init model cma array', name, cdata, var)\n",
    "        \n",
    "        self._params.append(name)\n",
    "        d[name] = var\n",
    "        if name in self._uninitialized_params:\n",
    "            del self._uninitialized_params[name]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP_FPGA(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_units, n_out):\n",
    "        super(MLP_FPGA, self).__init__(\n",
    "            # the size of the inputs to each layer will be inferred\n",
    "            l1=_Linear(None, n_units, nobias=True),  # n_in -> n_units\n",
    "            l2=_Linear(None, n_units, nobias=True),  # n_units -> n_units\n",
    "            l3=_Linear(None, n_out, nobias=True),  # n_units -> n_out\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if False:\n",
    "            h1 = self.l1(x)\n",
    "            print(h1.data)\n",
    "            h2 = self.l2(h1)\n",
    "            h3 = self.l3(h2)\n",
    "            return h3\n",
    "        \n",
    "        h = self.l1(x)\n",
    "        print(h)\n",
    "        h1 = F.relu(h)\n",
    "        print(\"h1 done\")\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        print(\"h2 done\")\n",
    "        h3 = self.l3(h2)\n",
    "        print(\"h3 done\")\n",
    "        print(x.shape)\n",
    "        print(h1.shape)\n",
    "        print(h1.data)\n",
    "        print(h2.shape)\n",
    "        print(h2.data)\n",
    "        print(h3.shape)\n",
    "        print(h3.data)\n",
    "        print(\"call done\")\n",
    "        return h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cma alloc\n",
      "init model cma array W <cdata 'float *' 0x30218000> W\n",
      "cma alloc\n",
      "init model cma array W <cdata 'float *' 0x36964000> W\n",
      "cma alloc\n",
      "init model cma array W <cdata 'float *' 0x36963000> W\n"
     ]
    }
   ],
   "source": [
    "memmanager.xlnk_reset()\n",
    "mlp_fpga = MLP_FPGA(n_units=32, n_out=10)\n",
    "\n",
    "resume = \"../examples/mnist/mnist_iter_12000.npz\"\n",
    "chainer.serializers.load_npz(resume, mlp_fpga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 入力画像をCMA-arrayに変換\n",
    "if False:\n",
    "    in_fpga, cdata = init_contiguous_ndarray((1, 784))\n",
    "    in_fpga = Variable(in_fpga)\n",
    "    in_fpga.cdata = cdata\n",
    "    print('init input cma array', cdata)\n",
    "    np.copyto(in_fpga.data, input_image.data)\n",
    "else:\n",
    "    in_fpga = input_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Buffer Count': 3,\n",
       " 'CMA Memory Available': 21188608,\n",
       " 'CMA Memory Usage': 105728}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memmanager.cma_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cma alloc\n",
      "cma alloc\n",
      "<var@302c4910>\n",
      "h1 done\n",
      "cma alloc\n",
      "cma alloc\n",
      "h2 done\n",
      "cma alloc\n",
      "cma alloc\n",
      "h3 done\n",
      "(1, 784)\n",
      "(1, 32)\n",
      "[[ 3.05095577  0.          2.55680013  4.07168865  1.99023378  1.09072948\n",
      "   0.          4.49700737  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]]\n",
      "(1, 32)\n",
      "[[ 1.10642385  0.          0.08190703  0.          0.          2.12742639\n",
      "   4.6531868   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]]\n",
      "(1, 10)\n",
      "[[-1.36190712  3.29412651 -0.30608779  1.43432307 -2.61085033 -0.78231484\n",
      "  -3.06695724 -0.66578758 -0.97282892  1.06473207]]\n",
      "call done\n",
      "[[ 0.00701601  0.73820955  0.02016631  0.11494161  0.00201224  0.01252575\n",
      "   0.00127525  0.01407378  0.01035296  0.07942659]]\n",
      "result 1\n",
      "seikai 5\n"
     ]
    }
   ],
   "source": [
    "h = mlp_fpga(in_fpga)\n",
    "#print(h.data)\n",
    "h = F.softmax(h)\n",
    "print(h.data)\n",
    "y = F.argmax(h)\n",
    "print(\"result\", y.data)\n",
    "print(\"seikai\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-94e6e27230f3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-94e6e27230f3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [[ 3.05095577 -2.61691952  2.55680013  4.07168865  1.99023378  1.09072948\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "[[ 3.05095577 -2.61691952  2.55680013  4.07168865  1.99023378  1.09072948\n",
    "  -1.82831872  4.49700737  5.57241726 -4.70780516 -2.25808644 -4.83468103\n",
    "   3.18601227 -3.28089046 -0.62773103 -0.6149773  -0.7455532   2.0017643\n",
    "   0.73404318  3.90470552  3.48775458  3.08954358 -0.47251615 -0.90851831\n",
    "  -0.327535    3.60635543  3.32248259 -3.12803578  3.87468791  6.82556391\n",
    "  -0.1521184   4.46334553]]\n",
    "cma alloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp_fpga.l1.W.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " %timeit -n 2 -o mlp_cpu(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " %timeit -n 2 -o mlp_fpga(in_fpga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "memmanager.xlnk_reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
